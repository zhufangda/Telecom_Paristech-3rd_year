{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#LAB:-Random-Projections-:-SOLUTIONS\" data-toc-modified-id=\"LAB:-Random-Projections-:-SOLUTIONS-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>LAB: Random Projections : SOLUTIONS</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Authors:-R.-M.-Gower\" data-toc-modified-id=\"Authors:-R.-M.-Gower-1.0.0.1\"><span class=\"toc-item-num\">1.0.0.1&nbsp;&nbsp;</span>Authors: R. M. Gower</a></span></li></ul></li></ul></li><li><span><a href=\"#Aim\" data-toc-modified-id=\"Aim-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Aim</a></span></li><li><span><a href=\"#VERY-IMPORTANT\" data-toc-modified-id=\"VERY-IMPORTANT-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>VERY IMPORTANT</a></span></li></ul></li><li><span><a href=\"#Gentle-reminder:-no-evaluation-if-you-don't-respect-this-EXACTLY\" data-toc-modified-id=\"Gentle-reminder:-no-evaluation-if-you-don't-respect-this-EXACTLY-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gentle reminder: no evaluation if you don't respect this EXACTLY</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#How-to-construct-the-name-of-your-file\" data-toc-modified-id=\"How-to-construct-the-name-of-your-file-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>How to construct the name of your file</a></span></li></ul></li><li><span><a href=\"#EXERCISE-1:\" data-toc-modified-id=\"EXERCISE-1:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>EXERCISE 1:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Corollary-of-Range-Space-Preserving-Theorem\" data-toc-modified-id=\"Corollary-of-Range-Space-Preserving-Theorem-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Corollary of Range Space Preserving Theorem</a></span></li><li><span><a href=\"#End-Corollary\" data-toc-modified-id=\"End-Corollary-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>End Corollary</a></span></li></ul></li><li><span><a href=\"#Exercise-2:\" data-toc-modified-id=\"Exercise-2:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Exercise 2:</a></span></li><li><span><a href=\"#Load-and-test-easier-data-set-anthracyclineTaxaneChemotherapy\" data-toc-modified-id=\"Load-and-test-easier-data-set-anthracyclineTaxaneChemotherapy-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Load and test easier data set <em>anthracyclineTaxaneChemotherapy</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#if-fetch_openml-fails\" data-toc-modified-id=\"if-fetch_openml-fails-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>if fetch_openml fails</a></span></li></ul></li><li><span><a href=\"#Load-and-test-HARDER-data-set-sector.scale\" data-toc-modified-id=\"Load-and-test-HARDER-data-set-sector.scale-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Load and test HARDER data set <em>sector.scale</em></a></span></li><li><span><a href=\"#Bonus-question\" data-toc-modified-id=\"Bonus-question-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Bonus question</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Random Projections : SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Authors: R. M. Gower\n",
    "\n",
    "## Aim\n",
    "\n",
    "The aim of this material is to\n",
    "- to show that in practice dimension reduction can be used with no loss of accuracy on some problem\n",
    "- code efficient sparse random projections\n",
    "- apply sparse random projections together with knearestneighbors\n",
    "\n",
    "\n",
    "## VERY IMPORTANT\n",
    "\n",
    "- This work **must be done by pairs of students**.\n",
    "- **Each** student must send their jupyter notebook **before the 24th of october at 23:59** to **gowerrobert@gmail.com**\n",
    "- This means that **each student in the pair sends the same file**\n",
    "- The **name of the file must be** constructed as in the next cell\n",
    "\n",
    "# Gentle reminder: no evaluation if you don't respect this EXACTLY\n",
    "\n",
    "### How to construct the name of your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:55.045257Z",
     "start_time": "2018-10-22T08:54:55.039274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab1_zhu_fangda_and_wang_yuqing.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Change here using YOUR first and last names\n",
    "fn1 = \"Fangda\"\n",
    "ln1 = \"ZHU\"\n",
    "fn2 = \"Yuqing\"\n",
    "ln2 = \"WANG\"\n",
    "\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(), \n",
    "                        [\"lab1\", ln1, fn1, \"and\", ln2, fn2])) + \".ipynb\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:55.212809Z",
     "start_time": "2018-10-22T08:54:55.209816Z"
    }
   },
   "outputs": [],
   "source": [
    "#Throughout the notebook you will find commented boxes like this one\n",
    "\n",
    "### TODO ###   \n",
    "# please implement blabla\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These boxes need to be replaced by code as explained in the boxes.\n",
    "Solutions will online tomorrow. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:55.844118Z",
     "start_time": "2018-10-22T08:54:55.496052Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "try:\n",
    "    %load_ext memory_profiler\n",
    "except:\n",
    "    print(\"Please run !ip install memory_profiler \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:55.975773Z",
     "start_time": "2018-10-22T08:54:55.881022Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "from scipy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:57.512668Z",
     "start_time": "2018-10-22T08:54:56.005688Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression    #Logistic Regression\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "def get_data(dataname):\n",
    "    data = load_svmlight_file(dataname)\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1: \n",
    "\n",
    "Use LogisticRegression classifier of Scikit-learn to experimentally confirm the following corollary proven in class and test random sparse projections\n",
    "\n",
    "### Corollary of Range Space Preserving Theorem  \n",
    "\n",
    "Let \n",
    "$$ X = [x_1, \\ldots, x_n]^\\top \\in \\mathbb{R}^{n\\times d},$$\n",
    "be our data matrix and let\n",
    "$$ X X^\\top = [\\hat{x}_1, \\ldots, \\hat{x}_n]^\\top \\in \\mathbb{R}^{n\\times n}. $$\n",
    "We can find a solution to the following training problem\n",
    "$$ w^* \\in \\min_{w \\in \\mathbb{R}^d}  \\frac{1}{n}\\sum_{i=1}^n \\ell_i(\\langle x_i,w \\rangle) \\hspace{3cm} (I)$$\n",
    "by instead solving \n",
    "$$ \\hat{w}^* \\in \\min_{w \\in \\mathbb{R}^n}  \\frac{1}{n}\\sum_{i=1}^n \\ell_i(\\langle \\hat{x}_i,w \\rangle) \\hspace{3cm} (II)$$\n",
    "and recover the solution via $ w^* = X^\\top \\hat{w}^*.$\n",
    "\n",
    "**NOTE:** The matrix $X$ is transposed with respect to the data matrix defined in class and in the lectures ! Be careful with dimnensions!\n",
    "### End Corollary\n",
    "\n",
    "1) Show that by setting the regularization parameter close to zero (C = 10^9) in LogisticRegression, the score obtained by training using $X$ and $X^\\top X$ is the same\n",
    "  \n",
    "2) Compute a solution $w^*_1$  by directly solving (I).  Compare this $w^*_1$ to the recovered solution $X^\\top \\hat{w}^*$. Are they the same? Justify based on Corollary.\n",
    "\n",
    "3) Using a random generated gaussian matrix $W \\in\\mathbb{R}^{d\\times r}$ , project the data matrix $X \\rightarrow XW$. Test for different values of r and\n",
    "apply logistic regression to the resulting projected matrix. Can you explain what you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:57.690180Z",
     "start_time": "2018-10-22T08:54:57.560527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 data points and 2000 features\n"
     ]
    }
   ],
   "source": [
    "# download the colon-cancer data set from \n",
    "# https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/colon-cancer.bz2\n",
    "# Unpack and place in the same folder as this python notebook\n",
    "dataname = \"colon-cancer\"  \n",
    "X, y = get_data(dataname)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "n, d = X_train.shape\n",
    "print('{n} data points and {d} features'.format(n = n,d =d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:57.764980Z",
     "start_time": "2018-10-22T08:54:57.731071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 1.000\n",
      "Accuracy on the training set: 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\zhufa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "C0 = 10**9 # 0.0005 # inverse of the regularization parameter, i.e, C = 1/lambda\n",
    "log_reg = LogisticRegression(C = C0) # , multi_class = \"multinomial\"\n",
    "log_reg.fit(X_train, y_train)\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:57.885657Z",
     "start_time": "2018-10-22T08:54:57.855739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 1.000\n",
      "Accuracy on the training set: 0.619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9405387538089003"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO ###   \n",
    "# 2)  Compute a solution $w^*_1$  by directly solving (I).  \n",
    "# Compare this $w^*_1$ to the recovered solution $X^\\top \\hat{w}^*$.\n",
    "# Are they the same? Justify based on Corollary.\n",
    "X_train_ = X_train.dot(X_train.T)\n",
    "X_test_ = X_test.dot(X_train.T)\n",
    "log_reg_ = LogisticRegression(C = C0, solver='liblinear')\n",
    "log_reg_.fit(X_train_,y_train)\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg_.score(X_train_,y_train)))\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg_.score(X_test_,y_test)))\n",
    "w = log_reg.coef_\n",
    "w_hat = log_reg_.coef_*X_train\n",
    "np.sum(w - w_hat)\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of the difference between $X$ and $X^\\top X$ is 1.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:58.330466Z",
     "start_time": "2018-10-22T08:54:57.957466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project dimension   41 gives: (train, test) =  (1.0000, 0.5714)\n",
      "project dimension   43 gives: (train, test) =  (1.0000, 0.5714)\n",
      "project dimension   45 gives: (train, test) =  (1.0000, 0.7143)\n",
      "project dimension   47 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   49 gives: (train, test) =  (1.0000, 0.5714)\n",
      "project dimension   51 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   53 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   55 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   57 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   59 gives: (train, test) =  (1.0000, 0.7143)\n",
      "project dimension   61 gives: (train, test) =  (1.0000, 0.7143)\n",
      "project dimension   63 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   65 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   67 gives: (train, test) =  (1.0000, 0.6190)\n",
      "project dimension   69 gives: (train, test) =  (1.0000, 0.6190)\n",
      "project dimension   71 gives: (train, test) =  (1.0000, 0.7619)\n",
      "project dimension   73 gives: (train, test) =  (1.0000, 0.7143)\n",
      "project dimension   75 gives: (train, test) =  (1.0000, 0.6190)\n",
      "project dimension   77 gives: (train, test) =  (1.0000, 0.6667)\n",
      "project dimension   79 gives: (train, test) =  (1.0000, 0.6190)\n",
      "project dimension   81 gives: (train, test) =  (1.0000, 0.6190)\n",
      "Best score was for r =   71 with: (train, test) =  (1.0000, 0.7619)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TODO ### \n",
    "## Choose a range of different projected dimensions to test\n",
    "## project_dimensions = range(???)\n",
    "#############\n",
    "test_accuracy = []\n",
    "training_accuracy = []\n",
    "s = 2*X_train.shape[0]\n",
    "project_dimensions = np.arange(X_train.shape[0],s,2)\n",
    "W = np.random.normal(0,1,X_train.shape[1]* 2*X_train.shape[0]).reshape(X_train.shape[1],2*X_train.shape[0])\n",
    "for r in project_dimensions: \n",
    "    ### TODO ###   \n",
    "    # 3)    project the data matrix $X \\rightarrow XW$ using Gaussian and fit, \n",
    "    #      transform and score using Logstic Regression\n",
    "    # trainscore =  ??\n",
    "    # training_accuracy.append(trainscore)\n",
    "    # testscore = ??\n",
    "    # test_accuracy.append(testscore)\n",
    "    W_ = W[:,:r]\n",
    "    X_train_ = X_train.dot(W_)\n",
    "    X_test_ = X_test.dot(W_)\n",
    "    log_reg_ = LogisticRegression(C = C0, solver='liblinear')\n",
    "    log_reg_.fit(X_train_,y_train)\n",
    "    trainscore = log_reg_.score(X_train_,y_train)\n",
    "    training_accuracy.append(trainscore)\n",
    "    testscore = log_reg_.score(X_test_,y_test)\n",
    "    test_accuracy.append(testscore)\n",
    "    #############\n",
    "    print (\"project dimension %4d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))\n",
    "# coef_recover= log_regt.coef_.dot(X_train.transpose())\n",
    "\n",
    "plt.plot(project_dimensions,training_accuracy, label='Accuracy of the training set')\n",
    "plt.plot(project_dimensions,test_accuracy, label='Accuracy of the test set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Projected Dimension')\n",
    "plt.legend()\n",
    "index_max = np.argmax(test_accuracy)\n",
    "print(\"Best score was for r =%5d with: (train, test) =  (%.4f, %.4f)\"% (project_dimensions[index_max], training_accuracy[index_max],test_accuracy[index_max]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Gaussian random projection can act like a regularizor and increase the prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Now we will work with large text based data set. For this you need to code the following random transform $W \\in \\mathbb{R}^{d \\times r}$ that take a sparsity parameter $s$ as an input:\n",
    "\n",
    "$$ W_{ij}  = \\sqrt{\\frac{s}{r}}\n",
    "\\begin{cases}\n",
    "1 \\quad & \\mbox{with probability }\\frac{1}{2s} \\\\\n",
    "0 \\quad & \\mbox{with probability }1-\\frac{1}{s} \\\\\n",
    "-1 \\quad & \\mbox{with probability }\\frac{1}{2s} \n",
    "\\end{cases}$$\n",
    "\n",
    "* Code a function Generate_Sparse_Transform$(s,r,d)$ that takes an input  \n",
    "   * sparsity parameter  $s$\n",
    "   * input dimension $d \\in \\mathbb{N}$\n",
    "   * lower dimensional projected dimension $r \\in \\mathbb{N}$\n",
    "and gives as output a random transform,  stored in an efficient format\n",
    "\n",
    "* Code a function Apply_Sparse_Transform$(R,X)$ that takes an input\n",
    "   * the random transform $W$ as generated by  Generate\\_sparse\\_transform$(s,r,d)$\n",
    "   * a given data matrix $X \\in \\mathbb{R}^{n\\times d}$\n",
    "the output will be $XW$. Note that this looks different then our class notes where we have $W^\\top X.$ The reason for this is that the data is transposed here!\n",
    "\n",
    "\n",
    "*Note* if you have not implemented this efficiently, you will probably run out of memory!  \n",
    "\n",
    "\n",
    "We will test if random projections are able to preserve pairwise distances by applying K-Neighrest Neighbors to projected data.\n",
    "\n",
    "1) Code the above two functions (their stub is provided below)\n",
    "\n",
    "\n",
    "2) Load the data set X. Then fit, transform and score sklearn's KNeighborsClassifier on this data, where \n",
    "$X = $ {anthracyclineTaxaneChemotherapy, sector.scale}. Below you will find how to load this data.\n",
    "\n",
    "3) Repeat the previous step, but first randomly project that data using X -> XW. Repeat this test for different values of the sparsity parameter s and projected dimension parameter r. What can you conclude? \n",
    "\n",
    "*Hint* As a rule of thumb $s = \\sqrt{r}$ often works well, and is a good trade off between sparsity and project dimension size. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:54:58.445185Z",
     "start_time": "2018-10-22T08:54:58.430201Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.utils.extmath import safe_sparse_dot   ## <-- I recommend using this function\n",
    "from sklearn.utils.random import sample_without_replacement  ## <-- I recommend using this function\n",
    "\n",
    "def GenerateSparseTransform(s,r,d):\n",
    "    '''\n",
    "    Implement this function. Make sure that W is a sparse matrix.\n",
    "    \n",
    "    Input : \n",
    "        s : sparsity parameter s\n",
    "        r : \n",
    "        d : input dimension\n",
    "    \n",
    "    Returns:\n",
    "        W : a sparse matrix, of size d by r\n",
    "    '''\n",
    "    a = [1, 0, -1]\n",
    "    size = (d, r)\n",
    "    p = [1/(2*s), 1-1/s, 1/(2*s)]\n",
    "    W = np.sqrt(s/r) * np.random.choice(a,size,p=p)\n",
    "    W = scipy.sparse.csr_matrix(W)\n",
    "    \n",
    "    return W\n",
    "\n",
    "def GenerateSparseTransform2(s,r,d):\n",
    "    '''\n",
    "    Implement this function. Make sure that W is a sparse matrix.\n",
    "    \n",
    "    Input : \n",
    "        s : sparsity parameter s\n",
    "        r : \n",
    "        d : input dimension\n",
    "    \n",
    "    Returns:\n",
    "        W : a sparse matrix, of size d by r\n",
    "    '''\n",
    "\n",
    "    p = np.sqrt(s/r)\n",
    "    W = scipy.sparse.rand(d, r, density=1/s, format='lil')\n",
    "    V = scipy.sparse.find(W)\n",
    "    for i,j,v in zip(V[0], V[1], V[2]):\n",
    "        W[i, j] = p if v >0.5 else -p\n",
    "            \n",
    "    return W\n",
    "\n",
    "def GenerateSparseTransform3(s,r,d):\n",
    "    '''\n",
    "    Implement this function. Make sure that W is a sparse matrix.\n",
    "    \n",
    "    Input : \n",
    "        s : sparsity parameter s\n",
    "        r : \n",
    "        d : input dimension\n",
    "    \n",
    "    Returns:\n",
    "        W : a sparse matrix, of size d by r\n",
    "    '''\n",
    "\n",
    "    p = np.sqrt(s/r)\n",
    "    W = scipy.sparse.rand(d, r, density=1/s, format='lil')\n",
    "    W[W>0.50] = -1\n",
    "    W[W>0] = -p\n",
    "    W[W == -1] = p\n",
    "    \n",
    "            \n",
    "    return W\n",
    "\n",
    "def ApplySparseTransform(W,X_):\n",
    "#     W   : Sparse randomly generated matrix of size d by r\n",
    "#     X_  : Data matrix to be compressed, of size n by d\n",
    "#    NOTE: The dimensions of W and X_ are such that the product X_*W is defined (which is different that what we used in class)\n",
    "    ### TODO ### \n",
    "    ##  Implement this function. Make sure that W is a sparse matrix!\n",
    "    Xtransformed = safe_sparse_dot(X_,W.todense())\n",
    "    #############\n",
    "    return Xtransformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We came up with 3 different ways to create the sparse matrix. The first way is to create the matrix we need, then store it into a sparse matrix. The second and the third  way to create a random sparse matrix, then modifiy the elements' value and sign. In the next step, we will compare these three ways and finally choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:55:48.873391Z",
     "start_time": "2018-10-22T08:54:58.536915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_ApplySparseTransform (__main__.UtilsTest) ... ok\n",
      "test_GenerateSparseTransform (__main__.UtilsTest) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 280 ms\n",
      "peak memory: 187.95 MiB, increment: 54.51 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_GenerateSparseTransform2 (__main__.UtilsTest) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 56\n",
      "Wall time: 8.06 s\n",
      "peak memory: 253.47 MiB, increment: 119.28 MiB\n",
      "Size: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_GenerateSparseTransform3 (__main__.UtilsTest) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.9 s\n",
      "peak memory: 277.70 MiB, increment: 141.84 MiB\n",
      "Size: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 50.210s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UtilsTest(unittest.TestCase):\n",
    "    \n",
    "    def test_GenerateSparseTransform(self):\n",
    "        %time GenerateSparseTransform(4,2000,2000)\n",
    "        %memit GenerateSparseTransform(4,2000,2000)\n",
    "        s,r,d = 4,2000,2000\n",
    "        W = GenerateSparseTransform(s,d,r)\n",
    "        A = scipy.sparse.find(W)\n",
    "        nb_nonzero = len(A[0])\n",
    "        print('Size:',sys.getsizeof(W))\n",
    "        self.assertAlmostEqual(1-1/s,1 - nb_nonzero/(d*r), 3)\n",
    "        self.assertAlmostEqual(1/(2.*s),np.sum(W>0)/(d*r), 3)\n",
    "        self.assertAlmostEqual(1/(2.*s),np.sum(W<0) /(d*r), 3)\n",
    "        \n",
    "    def test_GenerateSparseTransform2(self):\n",
    "        %time GenerateSparseTransform2(4,2000,2000)\n",
    "        %memit GenerateSparseTransform2(4,2000,2000)\n",
    "        s,r,d = 4,2000,2000\n",
    "        \n",
    "        W = GenerateSparseTransform2(s,d,r)\n",
    "        print('Size:',sys.getsizeof(W))\n",
    "        A = scipy.sparse.find(W)\n",
    "        nb_nonzero = len(A[0])\n",
    "        self.assertAlmostEqual(1-1/s,1 - nb_nonzero/(d*r), 3)\n",
    "        self.assertAlmostEqual(1/(2.*s),np.sum(W>0)/(d*r), 3)\n",
    "        self.assertAlmostEqual(1/(2.*s),np.sum(W<0) /(d*r), 3)\n",
    "        \n",
    "        \n",
    "    def test_GenerateSparseTransform3(self):\n",
    "        %time GenerateSparseTransform3(4,2000,2000)\n",
    "        %memit GenerateSparseTransform3(4,2000,2000)\n",
    "        s,r,d = 4,2000,2000\n",
    "        W = GenerateSparseTransform3(s,d,r)\n",
    "        print('Size:',sys.getsizeof(W))\n",
    "        A = scipy.sparse.find(W)\n",
    "        nb_nonzero = len(A[0])\n",
    "        self.assertAlmostEqual(1-1/s,1 - nb_nonzero/(d*r), 3)\n",
    "        self.assertAlmostEqual(1/(2.*s),np.sum(W>0)/(d*r), 3)\n",
    "        self.assertAlmostEqual(1/(2.*s),np.sum(W<0) /(d*r), 3)\n",
    "        \n",
    "\n",
    "    def test_ApplySparseTransform(self):\n",
    "        s,r,d = 4,2000,2000\n",
    "        W = GenerateSparseTransform(s,d,r)\n",
    "        X = scipy.sparse.rand(d, r, density=np.random.rand(1), format='lil')\n",
    "        XT = ApplySparseTransform(W, X)\n",
    "        sol = X.A.dot(W.A)\n",
    "        \n",
    "        self.assertAlmostEqual(np.sum(sol - XT.A), 0.0, 6)\n",
    "                \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(UtilsTest)        \n",
    "unittest.TextTestRunner(verbosity=2).run(suite)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:57:10.126684Z",
     "start_time": "2018-10-22T08:55:48.976080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 808 ms\n",
      "peak memory: 344.09 MiB, increment: 206.54 MiB\n",
      "Wall time: 26.3 s\n",
      "peak memory: 543.64 MiB, increment: 407.14 MiB\n",
      "Wall time: 11.9 s\n",
      "peak memory: 535.48 MiB, increment: 398.14 MiB\n"
     ]
    }
   ],
   "source": [
    "%time GenerateSparseTransform(4,200,61359)\n",
    "%memit GenerateSparseTransform(4,200,61359)\n",
    "%time GenerateSparseTransform2(4,200, 61359)\n",
    "%memit GenerateSparseTransform2(4,200,61359)\n",
    "%time GenerateSparseTransform3(4,200,61359)\n",
    "%memit GenerateSparseTransform3(4,200,61359)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the data's dimension is not too big, it seems that the first way can create a sparse matrix more quickly and costs less memory. But we are not sure if it works as well when the data's dimension grows larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:58:58.330817Z",
     "start_time": "2018-10-22T08:57:10.213446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n",
      "peak memory: 4562.05 MiB, increment: 4423.51 MiB\n",
      "Wall time: 28.2 s\n",
      "peak memory: 657.70 MiB, increment: 520.28 MiB\n",
      "Wall time: 12.6 s\n",
      "peak memory: 676.61 MiB, increment: 537.91 MiB\n"
     ]
    }
   ],
   "source": [
    "%time GenerateSparseTransform(70,4269,55197)\n",
    "%memit GenerateSparseTransform(70,4296,55197)\n",
    "%time GenerateSparseTransform2(70,4296,55197)\n",
    "%memit GenerateSparseTransform2(70,4296,55197)\n",
    "%time GenerateSparseTransform3(70,4296,55197)\n",
    "%memit GenerateSparseTransform3(70,4296,55197)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T12:10:44.988033Z",
     "start_time": "2018-10-21T12:10:44.981015Z"
    }
   },
   "source": [
    "According to the result of profiling, we find out that when the data's dimension grow large, the performence of the first implementation is much worse. It seems that the third way works best in this circumstance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test easier data set *anthracyclineTaxaneChemotherapy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T09:00:00.757434Z",
     "start_time": "2018-10-22T09:00:00.754441Z"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import fetch_openml\n",
    "#chemo = fetch_openml(name='anthracyclineTaxaneChemotherapy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if fetch_openml fails  \n",
    "**ALTERNATIVE HACK for loading the data**\n",
    "  \n",
    "* downloard the data from data set in arff format from: https://www.openml.org/d/1085\n",
    " \n",
    "* place data in the same folder as this notebook and run the code in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T09:00:10.202201Z",
     "start_time": "2018-10-22T09:00:01.545360Z"
    }
   },
   "outputs": [],
   "source": [
    "## ALTERNATIVE HACK for loading anthracyclineTaxaneChemotherapy ## \n",
    "from scipy.io import arff\n",
    "dataset = arff.loadarff('phpCLGrjq.arff')\n",
    "import pandas as pd\n",
    "Xdf = pd.DataFrame(dataset[0])\n",
    "Xy = Xdf.values\n",
    "n_rows, n_cols = Xy.shape\n",
    "X = Xy[:,:-1]\n",
    "X = np.float_(X)\n",
    "y = Xy[:,-1]\n",
    "y = (np.int_(y))*2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T09:00:01.923Z"
    }
   },
   "outputs": [],
   "source": [
    "# split test and training. Only use 20% of data for testing because data set is small. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) \n",
    "n, d = X_train.shape\n",
    "print('{n} trainig data points and {d} features'.format(n = n,d =d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T09:00:02.278Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) fit, transform and score the knn Classifier\n",
    "n_neighbors =2 # <-- use this number of neighbours\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "trainscore = knn.score(X_train, y_train)\n",
    "training_accuracy.append(trainscore)\n",
    "testscore = knn.score(X_test, y_test)\n",
    "test_accuracy.append(knn.score(X_test, y_test))\n",
    "print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (d, trainscore,testscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T09:00:02.624Z"
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "training_accuracy = []\n",
    "n_neighbors = 2  #< -- I recommend 2 neighbors\n",
    "\n",
    "### TODO ### \n",
    "## Choose a range of different projected dimensions to test\n",
    "## project_dimensions = range(???)\n",
    "## HINT: Only test project dimensions  r <= int(min(5*n,d/2))\n",
    "#############\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "project_dimensions = np.arange(n,int(min(5*n,d/2)),30)\n",
    "\n",
    "for r in project_dimensions:  \n",
    "    ### TODO ###   \n",
    "    # 3)    project the data matrix $X \\rightarrow XW$ using Gaussian and fit, \n",
    "    #      transform and score using knn\n",
    "    # W = GenerateSparseTransform(???)\n",
    "    # Xt_train = ApplySparseTransform(W,X_train)\n",
    "    # Xt_test =  ApplySparseTransform(W,X_test)\n",
    "    # trainscore =  ??\n",
    "    # training_accuracy.append(trainscore)\n",
    "    # testscore = ??\n",
    "    # test_accuracy.append(testscore)\n",
    "    W = GenerateSparseTransform(np.sqrt(r), r, d)\n",
    "    Xt_train = ApplySparseTransform(W,X_train)\n",
    "    Xt_test =  ApplySparseTransform(W,X_test)\n",
    "    knn.fit(Xt_train,y_train)\n",
    "    trainscore = knn.score(Xt_train, y_train)\n",
    "    training_accuracy.append(trainscore)\n",
    "    testscore = knn.score(Xt_test, y_test)\n",
    "    test_accuracy.append(testscore)\n",
    "    #############\n",
    "    print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))\n",
    "    \n",
    "list_proj_dims = list(project_dimensions)\n",
    "plt.plot(list_proj_dims,training_accuracy, label='Accuracy of the training set')\n",
    "plt.plot(list_proj_dims,test_accuracy, label='Accuracy of the test set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Projected Dimension')\n",
    "plt.legend()\n",
    "index_max = np.argmax(test_accuracy)\n",
    "print(\"Best score was for r =%5d with: (train, test) =  (%.4f, %.4f)\"% (list_proj_dims[index_max], training_accuracy[index_max],test_accuracy[index_max]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test HARDER data set *sector.scale*  \n",
    "**(only try this data set after successfully testing the anthracyclineTaxaneChemotherapy data set)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T09:00:03.652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the data set from:\n",
    "# https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/sector/sector.scale.bz2\n",
    "# place data in the same folder as this python notebook\n",
    "dataname = \"sector.scale\"  \n",
    "X, y = get_data(dataname)\n",
    "n, d = X.shape\n",
    "print('{n} data points and {d} features'.format(n = n,d =d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T09:00:04.526Z"
    }
   },
   "outputs": [],
   "source": [
    "# split test and training \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "n, d = X_train.shape\n",
    "print('{n} trainig data points and {d} features'.format(n = n,d =d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T09:00:07.500Z"
    }
   },
   "outputs": [],
   "source": [
    "### TODO ### \n",
    "## repeat the same experiments for this larger data set\n",
    "## HINT: Only test project dimensions r <= int(min(2*n,d/2))\n",
    "n_neighbors = 1 \n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "trainscore = knn.score(X_train, y_train)\n",
    "training_accuracy.append(trainscore)\n",
    "testscore = knn.score(X_test, y_test)\n",
    "test_accuracy.append(knn.score(X_test, y_test))\n",
    "print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (d, trainscore,testscore))\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T08:20:26.946Z"
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "training_accuracy = []\n",
    "n_neighbors = 1   ## <-- I recommend using this\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "#project_dimensions = np.arange(20,int(min(2*n,d/2)),300)\n",
    "project_dimensions = np.arange(n,int(min(2*n,d/2)),int(n/10))\n",
    "    \n",
    "for r in project_dimensions:  \n",
    "    ### TODO ###   \n",
    "    # 3)    project the data matrix $X \\rightarrow XW$ using Gaussian and fit, \n",
    "    #      transform and score using Logstic Regression\n",
    "    # W = GenerateSparseTransform(???)\n",
    "    # Xt_train = ApplySparseTransform(W,X_train)\n",
    "    # Xt_test =  ApplySparseTransform(W,X_test)\n",
    "    # trainscore =  ??\n",
    "    # training_accuracy.append(trainscore)\n",
    "    # testscore = ??\n",
    "    # test_accuracy.append(testscore)\n",
    "    W = GenerateSparseTransform3(np.sqrt(r), r, d)\n",
    "    Xt_train = ApplySparseTransform(W,X_train)\n",
    "    Xt_test =  ApplySparseTransform(W,X_test)\n",
    "    knn.fit(Xt_train,y_train)\n",
    "    trainscore = knn.score(Xt_train, y_train)\n",
    "    training_accuracy.append(trainscore)\n",
    "    testscore = knn.score(Xt_test, y_test)\n",
    "    test_accuracy.append(testscore)\n",
    "    #############\n",
    "    print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))\n",
    "\n",
    "list_proj_dims = list(project_dimensions)\n",
    "plt.plot(list_proj_dims,training_accuracy, label='Accuracy of the training set')\n",
    "plt.plot(list_proj_dims,test_accuracy, label='Accuracy of the test set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Projected Dimension')\n",
    "plt.legend()\n",
    "index_max = np.argmax(test_accuracy)\n",
    "print(\"Best score was for r =%5d with: (train, test) =  (%.4f, %.4f)\"% (list_proj_dims[index_max], training_accuracy[index_max],test_accuracy[index_max]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus question\n",
    "\n",
    "Using the Jonhson-Lindenstrauss Lemma, we can have an estimate for the projected dimension using\n",
    "\n",
    "$$r = \\frac{1}{\\epsilon^2}\\log(n/\\delta) $$\n",
    "\n",
    "1) Write a function for calculating this given suggested project dimension r. \n",
    "2) Test for each of the above data sets with \\epsilon = 0.05 = \\delta and compare to your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T08:20:27.281Z"
    }
   },
   "outputs": [],
   "source": [
    "#1\n",
    "def calculate_project_dimension(epsilon, delta, n):\n",
    "    return int(np.log(n/delta)/(epsilon**2))\n",
    "\n",
    "def calculate_score(X, y, knn):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    n, d = X_train.shape\n",
    "    epsilon = 0.05\n",
    "    delta = 0.05\n",
    "    r = calculate_project_dimension(epsilon,delta, n)\n",
    "    W = GenerateSparseTransform(np.sqrt(r), r, d)\n",
    "    Xt_train = ApplySparseTransform(W,X_train)\n",
    "    Xt_test =  ApplySparseTransform(W,X_test)\n",
    "    knn.fit(Xt_train,y_train)\n",
    "    trainscore = knn.score(Xt_train, y_train)\n",
    "    testscore = knn.score(Xt_test, y_test)\n",
    "    return trainscore, testscore, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T08:20:27.464Z"
    }
   },
   "outputs": [],
   "source": [
    "#2\n",
    "#colon-cancer\n",
    "dataname = \"colon-cancer\"  \n",
    "X, y = get_data(dataname)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "n, d = X_train.shape\n",
    "epsilon = 0.05\n",
    "delta = 0.05\n",
    "r = calculate_project_dimension(epsilon,delta, n)\n",
    "W = np.random.normal(0,1,X_train.shape[1]*r).reshape(X_train.shape[1],r)\n",
    "Xt_train = X_train.dot(W)\n",
    "Xt_test = X_test.dot(W)\n",
    "log_reg_ = LogisticRegression(C = C0, solver='liblinear')\n",
    "log_reg_.fit(Xt_train,y_train)\n",
    "trainscore = log_reg_.score(Xt_train, y_train)\n",
    "testscore = log_reg_.score(Xt_test, y_test)\n",
    "print (\"Using the Jonhson-Lindenstrauss Lemma with the datatset colon-cancer, project dim %5d gives: (train, test) =  (%.4f, %.4f)\" \n",
    "           % (r, trainscore,testscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Jonhson-Lindenstrauss Lemma on the \"colon-cancer\" dataset, we calculate the r = 2683, which is more than it's own dimension. So the final result is worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T08:20:27.799Z"
    }
   },
   "outputs": [],
   "source": [
    "#anthracyclineTaxaneChemotherapy\n",
    "Xdf = pd.DataFrame(dataset[0])\n",
    "Xy = Xdf.values\n",
    "n_rows, n_cols = Xy.shape\n",
    "X = Xy[:,:-1]\n",
    "X = np.float_(X)\n",
    "y = Xy[:,-1]\n",
    "y = (np.int_(y))*2-3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "n, d = X_train.shape\n",
    "r = calculate_project_dimension(epsilon,delta, n)\n",
    "W = GenerateSparseTransform3(np.sqrt(r), r, d)\n",
    "Xt_train = ApplySparseTransform(W,X_train)\n",
    "Xt_test =  ApplySparseTransform(W,X_test)\n",
    "n_neighbors = 2\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(Xt_train,y_train)\n",
    "trainscore = knn.score(Xt_train, y_train)\n",
    "testscore = knn.score(Xt_test, y_test)\n",
    "print (\"Using the Jonhson-Lindenstrauss Lemma with the datatset Chemo, project dim %5d gives: (train, test) =  (%.4f, %.4f)\" \n",
    "           % (r, trainscore,testscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Jonhson-Lindenstrauss Lemma, the dimension is reduced to 3063, which is much bigger than 5n. And we can see that the predict score is slightly better than the best result before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-22T08:20:28.150Z"
    }
   },
   "outputs": [],
   "source": [
    "#sector.scale\n",
    "dataname = \"sector.scale\"  \n",
    "X, y = get_data(dataname)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "n, d = X_train.shape\n",
    "r = calculate_project_dimension(epsilon,delta, n)\n",
    "W = GenerateSparseTransform3(np.sqrt(r), r, d)\n",
    "Xt_train = ApplySparseTransform(W,X_train)\n",
    "Xt_test =  ApplySparseTransform(W,X_test)\n",
    "n_neighbors = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(Xt_train,y_train)\n",
    "trainscore = knn.score(Xt_train, y_train)\n",
    "testscore = knn.score(Xt_test, y_test)\n",
    "print (\"Using the Jonhson-Lindenstrauss Lemma with the datatset sector.scale, project dim %5d gives: (train, test) =  (%.4f, %.4f)\" \n",
    "           % (r, trainscore,testscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With the Jonhson-Lindenstrauss Lemma, we get the dimension of 4544, it's not far from n. Comparing the predict score with the best score we got before, which is 0.8823, it seems that the score is slightly lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
